{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space Model\n",
    "We are interested in using this data to build statistical models. So, we now need to **vectorize** this data. The goal is to find a way to represent the data so that the computer can understand it.\n",
    "\n",
    "### Bag of words\n",
    "A bag of words represents each document in a corpus as a series of features. Most commonly, the features are the collection of all unique words in the vocabulary of the entire corpus. The values are usually the count of the number of times that word appears in the document, i.e. **term frequency**. \n",
    "\n",
    "A document $d$ is represented by a weight vector is $v_d=[w_{1,d} , w_{2,d},\\ldots, w_{N,d}]$ where $w_{t,d} = tf_{t,d}$, the term frequency of word $t$ in document $d$.\n",
    "\n",
    "A corpus is then represented as a matrix with one row per document and one column per unique word.\n",
    "\n",
    "### Scikit-Learn\n",
    "[Scikit-learn](http://scikit-learn.org/stable/) is machine learning library for the Python programming language. It features a wide range of machine learning algorithms for classification, regression and clustering. It also provides various supporting machine learning techniques such as cross validation, text vectorizer. Scikit-learn is designed to interoperate with the Python numerical and scientific libraries [NumPy](http://www.numpy.org/).\n",
    "\n",
    "Simple to use: import the required module and call it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer\n",
    "To build our initial bag of words count matrix, we will use scikit-learn's **CountVectorizer** class to transform our corpus into a bag of words representation. CountVectorizer expects as input a list of raw strings containing the documents in the corpus. It takes care of the tokenization, transformation to lowercase, filtering stop words, building the vocabulary etc. It also tabulates occurrance counts per document for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write code to import CountVectorizer\n",
    "from ...\n",
    "\n",
    "raw_docs_sample = [\"The dog sat on the mat.\", \n",
    "                   \"The cat sat on the mat!\",\n",
    "                   \"We have a mat in our house.\"]\n",
    "\n",
    "# Write code to create a CountVectorizer\n",
    "# Hint: use \"stop_word\" argument to specify English stop words\n",
    "vectorizer = ...\n",
    "\n",
    "# Write code to vectorize the sample text\n",
    "X_sample = ...\n",
    "\n",
    "X_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Vs Dense Matrices\n",
    "Dense matrices store every entry in the matrix. Sparse matrices only store the nonzero entries. Sparse matrices don't have a lot of extra features, and some algorithms may not work for them. You use them when you need to work with matrices that would be too big for the computer to handle them, but they are mostly zero, so they compress easily. Be aware of issues that may arise at:\n",
    "- dot product\n",
    "- slicing (row, column)\n",
    "\n",
    "In python these are taken care almost automatically, by using sparse dot product and implementations of csr and csc matrices (`scipy.sparse.csr_matrix`, `scipy.sparse.csc_matrix`, etc..). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Count Matrix:\")\n",
    "print(X_sample.todense())\n",
    "print(\"\\nWords in vocabulary:\")\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Weighting Scheme\n",
    "The tf-idf weighting scheme is an improvement over the simple term count or term frequency scheme we just saw. It is frequently used in text mining applications and has been shown to be effective. It combines two term statistics components:\n",
    "1. _Local component_: term count or term frequency (tf) reflects how important a word is to a document locally. For more details you can refer to [this link](https://nlp.stanford.edu/IR-book/html/htmledition/term-frequency-and-weighting-1.html).\n",
    "2. _Global component_: inverse document frequency (idf) of a word reflects how important the word is to the entire corpus or collection of documents. _Document frequency_ (df) of a word is the number of documents in the corpus where the word appears. A term with higher $df$ is a common term, thus carries less importance. $idf$ is an inverse function of $df$. So higher $idf$ means higher importance of the term globally. For more details you can refer to [this link](https://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html).\n",
    "\n",
    "The weight vector for document $d$ under tf-idf scheme is $v_d=[w_{1,d} , w_{2,d},\\ldots, w_{N,d}]$ where $w_{t,d}=tf_{t,d}\\times\\log\\frac{|D|}{|d'\\in D | t\\in d'| + 1}$ In the denominator we have added 1 to avoid division by zero, which is called smoothing. \n",
    "\n",
    "Scikit-learn has your back, it already provides the **TfidfVectorizer** module to compute TF-IDF matrix.\n",
    "\n",
    "Note: Scikit-learn uses a slightly different formula than that we saw today morning. You can refer to [corresponding documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html) to know more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code to import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Write code to create a TfidfVectorizer\n",
    "# Hint: use \"stop_word\" argument to specify English stop words\n",
    "tfidf = ...\n",
    "\n",
    "# Write code to vectorize the sample text\n",
    "X_tfidf_sample = ...\n",
    "\n",
    "print(\"TF-IDF Matrix:\\n\")\n",
    "print(X_tfidf_sample.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Bigger Collection\n",
    "We will use [**DBPedia** Ontology Classification Dataset](https://drive.google.com/open?id=0Bz8a_Dbh9QhbQ2Vic1kxMmZZQ1k). It includes first paragraphs of Wikipedia articles. Each paragraph is assigned one of **14 categories**. Here is an example of an abstract under *Written Work* catgory:\n",
    ">The Regime: Evil Advances/Before They Were Left Behind is the second prequel novel in the Left Behind series written by Tim LaHaye and Jerry B. Jenkins. It was released on Tuesday November 15 2005. This book covers more events leading up to the first novel Left Behind. It takes place from 9 years to 14 months before the Rapture.\n",
    "\n",
    "In this hands-on we will use 15,000 documents belonging to three categories, namely *Album*, *Film* and *Written Work*.\n",
    "\n",
    "The file **corpus.txt** supplied here, contains 15,000 documents. Each line of the file is a document.\n",
    "\n",
    "Now we will:\n",
    "   1. Load the documents as a list\n",
    "   2. Create TF-IDF vectors\n",
    "   \n",
    "Note: Each line of the file **corpus.txt** is a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code to load documents as a list\n",
    "# Hint: recall the strategy you used in the previous notebook\n",
    "raw_docs = ...\n",
    "\n",
    "print(\"Loaded \" + str(len(raw_docs)) + \" documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code to convert raw documents into TF-IDF matrix.\n",
    "\"\"\"\n",
    "Hint: - create a TfidfVectorizer, and do not forget to remove stopwords\n",
    "      - use fit_transform to vectorize raw_docs\n",
    "\"\"\"\n",
    "tfidf = ...\n",
    "X_tfidf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classifier\n",
    "Machine learning algorithms need a training set. In our text classification scenario, we need category or class labels for all 15000 documents in the collection.\n",
    "\n",
    "In our collection we have documents from three categories: \"Album\" (category 12), \"Film\" (category 13) and \"Written Work\" (category 14). For each document we know the labels. The labels are stored in **labels.txt** file. Each line of **corpus.txt** file corresponds to the label in the same line of file **labels.txt**.\n",
    "\n",
    "Lets load the labels.\n",
    "\n",
    "Note: Each line of the file **labels.txt** is a document.\n",
    "\n",
    "Verify that the number of loaded labels and number of loaded documents are same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15000 labels.\n"
     ]
    }
   ],
   "source": [
    "# Write code to load labels list from file 'labels.txt'\n",
    "# Hint: use the same strategy you used to load documents\n",
    "labels = ...\n",
    "\n",
    "print(\"Loaded \" + str(len(labels)) + \" labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When labels are read from a text file, Python by default interprets each label line as string. For computations we require integer labels. So, these strings are converted to integers while reading from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace string labels with numerical ones\n",
    "y = np.array([int(label) for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing\n",
    "\n",
    "As we wish to first train a model and then to see how well it is. So the norm is to divide the data into two parts:\n",
    " 1. **Training set:** Documents along with their class labels are used to train the model.\n",
    " 2. **Test set:** Documents are used for predicting the class labels using the trained classifier. However, the class labels of this set are kept *hidden* and are only revealed during evalutaion of the trained model, not before that.\n",
    "\n",
    "Note: Here we are splitting the data ourselves. In most of the datasets, training and test set are provided separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# package to split training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test =train_test_split(X_tfidf, y, test_size = 0.2, random_state = 256)\n",
    "\n",
    "print(\"Training set: \" + str(X_train.shape[0]) + \" documents.\")\n",
    "print(\"Test set: \" + str(X_test.shape[0]) + \" documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Classifier\n",
    "\n",
    "First we will use Multinomial Naive Bayes classifier. Scikit-learn provides the module **MultinomialNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code to import MultinomialNB\n",
    "from ...\n",
    "\n",
    "# Write code to create a MultinomialNB classifier\n",
    "classifierNB = ...\n",
    "\n",
    "# Write code to train the classifier using \"fit\" function.\n",
    "# Hint: you need to provide training data and labels for training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Now we will test the trained classifier on out kept hidden test data to see how well it did. \n",
    "\n",
    "Here we will look at the accuracy of the model, the simplest evaluation measure used in machine learning algorithms: $$accuracy = \\frac{\\text{number of correctly classified examples}}{\\text{total number of examples}}$$\n",
    "\n",
    "There are more informative and complex evaluaton measures, e.g. precision, recall, f-measure etc.\n",
    "\n",
    "Note: It is customary to report accuracy in percentage. So we convert the ratio into percentage.\n",
    "\n",
    "Again, Scikit-learn already provides the **accuracy_score** method for calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code to import accuracy_score method\n",
    "from ...\n",
    "\n",
    "# Write code to predict labels for the test set using the classifier you trained\n",
    "# Hint: use the \"predict\" method of the classifier\n",
    "predictionsNB = ...\n",
    "\n",
    "# Write code to calculate accuracy using \"accuracy_score\" method\n",
    "#Â Hint: you have to provide test labels and predicted labels to measure accuracy\n",
    "accuracyNB = ...\n",
    "\n",
    "print(\"Test accuracy: \" + str(accuracyNB * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Classifiers\n",
    "You have virtually an endless option to choose your classifier. Let's try some more.\n",
    "\n",
    "Method is simple: \n",
    "1. import relevant packages\n",
    "2. create an instance of the classifier\n",
    "3. `fit` with the training data and training labels\n",
    "4. `predict` with the test data\n",
    "5. evaluate by comparing  predicted labels and test labels\n",
    "\n",
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Write code to import Perceptron\n",
    "from ...\n",
    "\n",
    "# 2. Write code to create Perceptron classifier\n",
    "classifierPer = ...\n",
    "\n",
    "# 3. Write code to \"fit\" the classifier with training data and labels\n",
    "...\n",
    "\n",
    "# 4. Write code to \"predict\" labels for the test set\n",
    "predictionsPer = ...\n",
    "\n",
    "# 5. Write code to calculate accuracy\n",
    "accuracyPer = ...\n",
    "\n",
    "print(\"Test accuracy: \" + str(accuracyPer * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Write code to import RandomForestClassifier\n",
    "from ...\n",
    "\n",
    "# 2. Write code to create Random Forest classifier\n",
    "classifierRF = ...\n",
    "\n",
    "# 3. Write code to \"fit\" the classifier with training data and labels\n",
    "\n",
    "\n",
    "# 4. Write code to \"predict\" labels for the test set\n",
    "predictionsRF = ...\n",
    "\n",
    "# 5. Write code to report accuracy\n",
    "accuracyRF = ...\n",
    "\n",
    "print(\"Test accuracy: \" + str(accuracyRF * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
